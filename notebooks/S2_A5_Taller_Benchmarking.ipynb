{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3b8db6",
   "metadata": {},
   "source": [
    "# Sesión 2 Apartado 5 — Taller: Benchmarking\n",
    "\n",
    "En este taller aplicarás lo visto en las notebooks anteriores para comparar y seleccionar modelos de clasificación binaria de forma rigurosa.\n",
    "\n",
    "Qué pondrás en práctica (S2_A1 → S2_A4):\n",
    "- Entrenamiento de varios modelos base (LR, RF, SVM, KNN)\n",
    "- Preprocesado con escalado (especialmente útil para SVM/KNN)\n",
    "- Métricas de evaluación: Accuracy, F1, AUC y matriz de confusión\n",
    "- Validación cruzada (k-fold, estratificada) y estabilidad de resultados\n",
    "- Búsqueda de hiperparámetros con GridSearchCV (multi-métrica + refit)\n",
    "- Visualizaciones: matrices de confusión, curvas ROC/PR\n",
    "- (Opcional) Nested CV para estimar generalización de la selección de hiperparámetros\n",
    "- (Opcional) Persistencia del mejor modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a1c68e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (398, 30) Test shape: (171, 30)\n"
     ]
    }
   ],
   "source": [
    "# Dataset y configuración\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# División estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "\n",
    "# Vista rápida de los datos\n",
    "pd.DataFrame(X_train, columns=feature_names).head()\n",
    "\n",
    "# Modelos base del taller\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=500, random_state=RANDOM_STATE),\n",
    "    'RandomForest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'SVM': SVC(probability=True, random_state=RANDOM_STATE),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Utility: función para evaluar y devolver un dict con métricas\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, 'predict_proba') else None\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b448589f",
   "metadata": {},
   "source": [
    "## Paso 1 — Preprocesado\n",
    "Escala las features con `StandardScaler` y transforma `X_train` y `X_test`.\n",
    "\n",
    "Pistas:\n",
    "- Ajusta el scaler SOLO con `X_train` (fit), y luego transforma ambos (`transform`).\n",
    "- SVM y KNN suelen mejorar con datos escalados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e31a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled shapes: (398, 30) (171, 30)\n"
     ]
    }
   ],
   "source": [
    "# TODO 1: Preprocesado (rellena aquí)\n",
    "from sklearn.preprocessing import StandardScaler # <-- Escoge el preprocesado que quieras\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Ajusta con el train y transforma train/test\n",
    "X_train_scaled = None  # fit y transform en train\n",
    "X_test_scaled = None   # transform en test\n",
    "\n",
    "print('Scaled shapes:', X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985fdfb",
   "metadata": {},
   "source": [
    "## Paso 2 — Entrenamiento básico\n",
    "Entrena cada modelo con parámetros por defecto sobre `X_train_scaled`, evalúa en `X_test_scaled` con `evaluate_model(...)` y guarda los resultados en una lista `results` para crear un `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d60691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Entrenamiento y evaluación básica\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    # model.fit con train scaled\n",
    "    res = None  # evaluate_model con test scaled\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfdfed5",
   "metadata": {},
   "source": [
    "## Paso 3 — Ajuste rápido de hiperparámetros\n",
    "Usa `GridSearchCV`:\n",
    "- Para RandomForest: explora `n_estimators` y `max_depth` (puedes añadir `max_features`).\n",
    "- Para SVM: explora `C` y `kernel`.\n",
    "- Usa scoring multi-métrica (p. ej. `{'f1': 'f1', 'accuracy': 'accuracy'}`) y decide `refit`.\n",
    "- Evalúa los mejores modelos en test y compáralos con los baseline del Paso 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3: GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = \"f1\"\n",
    "param_grid = {\n",
    "    \"LogisticRegression\": {\"C\": [], \"penalty\": []},\n",
    "    \"RandomForest\": {\"n_estimators\": [], \"max_depth\": []},\n",
    "    \"SVM\": {\"C\": [], \"kernel\": []},\n",
    "    \"KNN\": {\"n_neighbors\": [], \"weights\": []},\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    grid = None  # GridSearchCV con model, param_grid[name], scoring, cv=5, n_jobs=-1\n",
    "    # grid.fit con train scaled\n",
    "    best_models[name + \"_grid\"] = grid.best_estimator_\n",
    "    print(f\"Best params for {name}: {grid.best_params_}\")\n",
    "\n",
    "# Evaluación de los mejores modelos\n",
    "best_results = []\n",
    "for name, model in best_models.items():\n",
    "    res = None  # evaluate_model con name, model y test scaled\n",
    "    best_results.append(res)\n",
    "\n",
    "tuned_results_df = pd.DataFrame(best_results)\n",
    "tuned_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67809158",
   "metadata": {},
   "source": [
    "## Paso 4 — Comparación y visualización\n",
    "- Crea una tabla comparativa combinando baseline (`results_df`) y modelos ajustados (`tuned_results_df`).\n",
    "- Grafica las métricas Accuracy, F1 y AUC por modelo.\n",
    "- Dibuja la matriz de confusión del mejor modelo (según tu criterio) y sus curvas ROC y Precision-Recall.\n",
    "- Responde en Markdown: ¿qué modelo elegirías para producción y por qué? (justifica con métricas y estabilidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b330d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4: Visualización comparativa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "\n",
    "all_results = pd.concat([results_df, tuned_results_df], ignore_index=True)\n",
    "print(all_results)\n",
    "\n",
    "# Barras comparativas\n",
    "_ = all_results.set_index(\"Model\")[[\"Accuracy\", \"F1\", \"AUC\"]].plot(\n",
    "    kind=\"bar\", figsize=(10, 6)\n",
    ")\n",
    "plt.title(\"Benchmarking: Accuracy, F1, AUC\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "\n",
    "# TODO: selecciona tu mejor modelo (por nombre) de all_results\n",
    "best_name = all_results.sort_values(\"F1\", ascending=False).iloc[0][\n",
    "    \"Model\"\n",
    "]  # puedes cambiar el criterio\n",
    "print(\"Best by F1:\", best_name)\n",
    "\n",
    "# Recupera el estimador entrenado correspondiente\n",
    "trained_estimators = {**models, **best_models}\n",
    "\n",
    "best_est = trained_estimators[best_name]\n",
    "\n",
    "y_pred_best = best_est.predict(X_test_scaled)\n",
    "# Si hay probabilidades, calcula curvas ROC/PR\n",
    "has_proba = hasattr(best_est, \"predict_proba\")\n",
    "y_proba_best = best_est.predict_proba(X_test_scaled)[:, 1] if has_proba else None\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = None  # confusion_matrix con y_test y y_pred_best\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix - {best_name}\")\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()\n",
    "\n",
    "# Curvas ROC y PR (si aplica)\n",
    "if y_proba_best is not None:\n",
    "    fpr, tpr, _ = None  # roc_curve con y_test y y_proba_best\n",
    "    precision, recall, _ = None  # precision_recall_curve con y_test y y_proba_best\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], \"--\")\n",
    "    plt.title(f\"ROC curve - {best_name}\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision)\n",
    "    plt.title(f\"Precision-Recall curve - {best_name}\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\n",
    "        f\"{best_name} no expone predict_proba; puedes usar decision_function o elegir otro modelo para curvas.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc3cde",
   "metadata": {},
   "source": [
    "## Paso 5 — Validación cruzada y estabilidad\n",
    "- Usa `cross_validate` con dos métricas (accuracy y f1) para los cuatro modelos sobre todo el conjunto (X, y) con `cv=5`.\n",
    "- Resume media y desviación estándar por modelo y métrica.\n",
    "- Genera predicciones out-of-fold con `cross_val_predict` para tu modelo favorito y dibuja su matriz de confusión OOF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5: Validación cruzada y OOF\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv = # StratifiedKFold con n_splits=5, shuffle=True, random_state=RANDOM_STATE\n",
    "scoring = {} # Añade accuracy y f1\n",
    "\n",
    "cv_rows = []\n",
    "for name, model in models.items():\n",
    "    scores = # cross_validate con model, X, y, cv=cv, scoring, n_jobs=-1\n",
    "    cv_rows.append({\n",
    "        'Model': name,\n",
    "        'cv_accuracy_mean': scores['test_accuracy'].mean(),\n",
    "        'cv_accuracy_std': scores['test_accuracy'].std(),\n",
    "        'cv_f1_mean': scores['test_f1'].mean(),\n",
    "        'cv_f1_std': scores['test_f1'].std(),\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_rows)\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "favorite = \"RandomForest\"\n",
    "y_oof = None  # cross_val_predict con models[favorite], X, y, cv=cv\n",
    "cm_oof = None  # confusion_matrix con y, y_oof\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_oof, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Matriz de confusión OOF - {favorite}\")\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567fb7a",
   "metadata": {},
   "source": [
    "## (Opcional) Paso 6 — Nested CV\n",
    "Implementa una nested CV para SVM o RF:\n",
    "- Outer CV (p.ej. 5 folds estratificada) para estimar rendimiento generalizado.\n",
    "- Inner GridSearchCV (como en Paso 3) para seleccionar hiperparámetros.\n",
    "- Reporta la media y desviación de la métrica en los folds externos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (opcional) 6: Nested CV scaffold\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "\n",
    "outer_cv = # StratifiedKFold con n_splits=5, shuffle=True, random_state=RANDOM_STATE\n",
    "inner_cv = # StratifiedKFold con n_splits=3, shuffle=True, random_state=RANDOM_STATE\n",
    "\n",
    "# Elige un modelo y su grid (ejemplo: SVM)\n",
    "base_est = models['SVM']  # <-- puedes cambiar\n",
    "param_grid = {\n",
    "    'C': [],\n",
    "    'kernel': []\n",
    "}\n",
    "\n",
    "clf = # GridSearchCV con base_est, param_grid, scoring='f1', cv=inner_cv, n_jobs=-1\n",
    "outer_scores = # cross_val_score con clf, X, y, scoring='f1', cv=outer_cv, n_jobs=-1\n",
    "print('Nested CV F1 (mean±std):', outer_scores.mean(), '±', outer_scores.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
